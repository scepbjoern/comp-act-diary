version: "3.9"

services:
  db:
    image: postgres:16-alpine
    container_name: compact-diary-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - ${DB_DATA_PATH}:/var/lib/postgresql/data
    # Externen Port nur freigeben, wenn nötig:
    # ports:
    #   - "${DB_PORT:-5432}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5

  app:
    container_name: compact-diary-app
    build:
      context: ..
      dockerfile: Dockerfile
      args:
        HTTP_PROXY: ${HTTP_PROXY}
        HTTPS_PROXY: ${HTTPS_PROXY}
        NO_PROXY: ${NO_PROXY}
        UID: ${UID:-1000}
        GID: ${GID:-1000}
        DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}?schema=public
        OPENAI_API_KEY: ${OPENAI_API_KEY}
        TOGETHERAI_API_KEY: ${TOGETHERAI_API_KEY}
        MAPBOX_ACCESS_TOKEN: ${MAPBOX_ACCESS_TOKEN:-}
        # Build-time variables for Next.js inlining
        NEXT_PUBLIC_MAPBOX_ACCESS_TOKEN: ${NEXT_PUBLIC_MAPBOX_ACCESS_TOKEN:-}
      network: host
    restart: unless-stopped
    environment:
      NODE_ENV: production
      # Aus Einzelwerten zusammengesetzt, keine Secrets im Repo
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}?schema=public
      # OpenAI transcription (server runtime) - for GPT-Transcribe models
      # Set OPENAI_API_KEY in your stack/Portainer env so this gets injected at runtime
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      # Optional server default model (fallback if client doesn't send one)
      OPENAI_TRANSCRIBE_MODEL: ${OPENAI_TRANSCRIBE_MODEL:-gpt-4o-mini-transcribe}
      # TogetherAI transcription (server runtime) - for Whisper models
      # Set TOGETHERAI_API_KEY in your stack/Portainer env so this gets injected at runtime
      TOGETHERAI_API_KEY: ${TOGETHERAI_API_KEY}
      # Optional server default model (fallback if client doesn't send one)
      TOGETHERAI_TRANSCRIBE_MODEL: ${TOGETHERAI_TRANSCRIBE_MODEL:-openai/whisper-large-v3}
      # TogetherAI LLM for text improvement
      TOGETHERAI_LLM_MODEL: ${TOGETHERAI_LLM_MODEL:-openai/gpt-oss-20b}
      # Image processing settings
      IMAGE_MAX_WIDTH: ${IMAGE_MAX_WIDTH:-1600}
      IMAGE_MAX_HEIGHT: ${IMAGE_MAX_HEIGHT:-1600}
      IMAGE_FORMAT: ${IMAGE_FORMAT:-webp}
      IMAGE_QUALITY: ${IMAGE_QUALITY:-80}
      # Audio handling settings
      MAX_AUDIO_FILE_SIZE_MB: ${MAX_AUDIO_FILE_SIZE_MB:-50}
      AUDIO_RETENTION_DAYS: ${AUDIO_RETENTION_DAYS:-365}
      AUDIO_COMPRESSION_BITRATE: ${AUDIO_COMPRESSION_BITRATE:-64}
      # Client-side variables (exposed to browser)
      NEXT_PUBLIC_OPENAI_TRANSCRIBE_MODEL: ${NEXT_PUBLIC_OPENAI_TRANSCRIBE_MODEL:-gpt-4o-mini-transcribe}
      NEXT_PUBLIC_TOGETHERAI_TRANSCRIBE_MODEL: ${NEXT_PUBLIC_TOGETHERAI_TRANSCRIBE_MODEL:-openai/whisper-large-v3}
      NEXT_PUBLIC_TRANSCRIBE_MODELS: ${NEXT_PUBLIC_TRANSCRIBE_MODELS:-openai/whisper-large-v3,gpt-4o-mini-transcribe,gpt-4o-transcribe}
      NEXT_PUBLIC_TOGETHERAI_LLM_MODEL: ${NEXT_PUBLIC_TOGETHERAI_LLM_MODEL:-openai/gpt-oss-20b}
      NEXT_PUBLIC_LLM_MODELS: ${NEXT_PUBLIC_LLM_MODELS:-openai/gpt-oss-20b,openai/gpt-oss-120b,mistralai/Mistral-7B-Instruct-v0.3,meta-llama/Llama-4-Scout-17B-16E-Instruct}
      # optional: NEXT_TELEMETRY_DISABLED: "1"
      SYNC_SCHEMA: ${SYNC_SCHEMA:-false}
      # Google Contacts Sync (OAuth 2.0)
      GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID:-}
      GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET:-}
      GOOGLE_REDIRECT_URI: ${GOOGLE_REDIRECT_URI:-} 
      DEEPGRAM_API_KEY: ${DEEPGRAM_API_KEY:-}
      MISTRAL_API_KEY: ${MISTRAL_API_KEY:-}
      MAPBOX_ACCESS_TOKEN: ${MAPBOX_ACCESS_TOKEN:-}
      NEXT_PUBLIC_MAPBOX_ACCESS_TOKEN: ${NEXT_PUBLIC_MAPBOX_ACCESS_TOKEN:-}
    depends_on:
      - db
    ports:
      - "${APP_PORT:-3000}:3000"
    # Persistente Uploads (Hostpfad -> Container /app/uploads). Siehe .env: PUBLIC_UPLOADS_PATH
    # Beispiel in .env:
    #   PUBLIC_UPLOADS_PATH=../uploads
    volumes:
      - ${PUBLIC_UPLOADS_PATH:-../uploads}:/app/uploads

  backup_db:
    container_name: compact-diary-db-backup
    image: postgres:16
    restart: unless-stopped
    volumes:
      - ${DB_BACKUP_PATH}:/dump
      - /etc/localtime:/etc/localtime:ro
    environment:
      PGHOST: db
      PGUSER: ${POSTGRES_USER}
      PGPASSWORD: "${POSTGRES_PASSWORD}"
      PGDATABASE: ${POSTGRES_DB}
      BACKUP_NUM_KEEP: "3"
      BACKUP_FREQUENCY: "8h"
      # Kompression steuerbar: Beispiele
      #   gzip:9   (starke Kompression, langsamer)
      #   lz4      (sehr schnell, etwas groesser)
      #   zstd:15  (sehr gute Ratio, schnell – wenn im Image verlinkt)
      BACKUP_COMPRESS: "gzip:6"
    depends_on:
      db:
        condition: service_healthy
    user: "${UID}:${GID}"
    entrypoint: |
      bash -c 'bash -s << "EOF"
      set -Eeuo pipefail
      log() { printf "[%s] %s\n" "$(date -u +%Y-%m-%dT%H:%M:%SZ)" "$*"; }
      trap "log \"Stop-Signal empfangen, beende Container\"; exit 0" SIGHUP SIGINT SIGTERM

      do_backup() {
        local ts outfile start end compress_opt
        ts=$$(date -u "+%Y-%m-%d_%H-%M-%S")
        log "Timestamp: $$ts"
        outfile="/dump/dump_$${ts}.dump"

        # Kompressionsparameter (PG16+: Methode[:Level] moeglich)
        if [ -n "${BACKUP_COMPRESS:-}" ]; then
          compress_opt=(--compress="${BACKUP_COMPRESS}")
        else
          compress_opt=(--compress=6)
        fi

        log "Backup startet → Datei: ${outfile} (compress: ${BACKUP_COMPRESS:-6})"
        start=$$SECONDS
        if pg_dump -h "$$PGHOST" -U "$$PGUSER" -d "$$PGDATABASE" -Fc \
                  "$${compress_opt[@]}" -f "$$outfile" \
                  2>"/dump/dump_$${ts}.stderr.log"; then
          end=$$SECONDS
          log "Backup OK (Dauer: $$((end-start))s, Groesse: $$(du -h "$$outfile" | awk '"'"'{print $$1}'"'"'))"
          [ -s "/dump/dump_$${ts}.stderr.log" ] || rm -f "/dump/dump_$${ts}.stderr.log"
        else
          end=$$SECONDS
          log "Backup FEHLGESCHLAGEN (Dauer: $$((end-start))s). Details: dump_$${ts}.stderr.log"
          return 1
        fi

        # Rotation
        local KEEP
        KEEP=$${BACKUP_NUM_KEEP:-3}
        shopt -s nullglob
        mapfile -t sorted < <(ls -1t /dump/dump_*.dump 2>/dev/null || true)
        if (("$${#sorted[@]}" > KEEP)); then
          log "Rotation: behalte $$KEEP neueste, entferne $$(( $${#sorted[@]} - KEEP )) aeltere"
          printf "%s\0" "$${sorted[@]:KEEP}" | xargs -0 -r rm --
        fi
      }

      log "Warte auf Datenbank $$PGHOST/$$PGDATABASE …"
      until pg_isready -h "$$PGHOST" -U "$$PGUSER" -d "$$PGDATABASE" >/dev/null 2>&1; do
        sleep 2
      done
      log "Datenbank erreichbar."
      mkdir -p /dump

      # Sofort-Backup beim Start
      if ! do_backup; then
        log "Erster Backup-Versuch fehlgeschlagen; neuer Versuch nach 60s"
        sleep 60
        do_backup || log "Warnung: Start-Backup wieder fehlgeschlagen"
      fi

      # Regelmaessige Backups
      while true; do
        sleep $${BACKUP_FREQUENCY:-8h}
        do_backup || log "Warnung: geplanter Backup-Versuch fehlgeschlagen"
      done
      EOF'
    labels:
      - "com.centurylinklabs.watchtower.enable=true"
      - "diun.enable=false"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h $$PGHOST -U $$PGUSER -d $$PGDATABASE"]
      interval: 10s
      timeout: 5s
      retries: 5

networks:
  default:
    name: comp-act-diary_default
    ipam:
      config:
        - subnet: 172.40.30.0/24